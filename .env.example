# AI Deep Research Assistant - Environment Variables

# =============================================================================
# WEB SEARCH CONFIGURATION
# =============================================================================
# Brave Search API (Required for web research)
BRAVE_API_KEY=your_brave_api_key_here

# =============================================================================
# LLM PROVIDER CONFIGURATION
# =============================================================================
# Default provider (OpenRouter is recommended for cost-effectiveness)
AI_SERVICE=openrouter  # Options: openrouter, openai, anthropic, gemini

# OpenRouter (Default - cost-effective with good model selection)
OPENROUTER_API_KEY=your_openrouter_api_key_here

# OpenAI (Alternative provider)
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic (Alternative provider)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Google Gemini (Alternative provider)  
GEMINI_API_KEY=your_gemini_api_key_here

# =============================================================================
# MODEL CONFIGURATION
# =============================================================================
# Small model for guardrail agent (cost optimization)
# OpenRouter format: provider/model-name
MODEL_CHOICE_SMALL=openai/gpt-4o-mini  # Or eg anthropic/claude-3-haiku-20240307

# Full model for research and synthesis (quality optimization)
MODEL_CHOICE=anthropic/claude-sonnet-4  # Or eg openai/gpt-4o, google/gemini-1.5-pro

# Model temperature and parameters
MODEL_TEMPERATURE=0.1
MODEL_TOP_P=0.9
MODEL_MAX_TOKENS=4096

# =============================================================================
# PERFORMANCE & CACHING CONFIGURATION
# =============================================================================
# Cache settings
CACHE_TTL_MINUTES=15
CACHE_MAX_SIZE=1000

# Rate limiting
BRAVE_RATE_LIMIT_DELAY=1.0  # Seconds between API calls
MAX_CONCURRENT_REQUESTS=5

# Performance targets
FIRST_TOKEN_TIMEOUT=2  # Seconds
END_TO_END_TIMEOUT=15  # Seconds

# =============================================================================
# OBSERVABILITY & MONITORING (Optional)
# =============================================================================
# Langfuse for LLM observability
LANGFUSE_PUBLIC_KEY=your_langfuse_public_key_here
LANGFUSE_SECRET_KEY=your_langfuse_secret_key_here
LANGFUSE_HOST=https://cloud.langfuse.com

# Logging configuration
LOG_LEVEL=INFO
LOG_FORMAT=json  # Options: json, text

# =============================================================================
# RESEARCH CONFIGURATION
# =============================================================================
# Search result limits
MAX_SEARCH_RESULTS=8
MAX_CITATIONS_PER_CLAIM=3

# Research depth settings
DEFAULT_RESEARCH_DEPTH=comprehensive  # Options: surface, comprehensive, exhaustive

# Confidence thresholds
MIN_CONFIDENCE_THRESHOLD=0.7
SYNTHESIS_CONFIDENCE_THRESHOLD=0.8

# =============================================================================
# CLI CONFIGURATION
# =============================================================================
# Display settings
ENABLE_RICH_FORMATTING=true
SHOW_PROGRESS_BARS=true
SHOW_CITATION_PREVIEWS=true

# Interactive settings
ENABLE_FOLLOW_UP_QUESTIONS=true
MAX_CONVERSATION_HISTORY=10

# =============================================================================
# DEVELOPMENT SETTINGS
# =============================================================================
# Debug mode
DEBUG=false
VERBOSE_LOGGING=false

# Testing
MOCK_BRAVE_API=false
TEST_MODE=false